# AI ä¼¦ç†ä¸ç¤¾ä¼š / AI Ethics and Society

## ç²¾é€‰èµ„æ–™ / Curated Resources

### â­ ç»å…¸ç²¾é€‰ / Canonical Picks

- Red Teaming Language Models to Reduce Harms â€” ç³»ç»ŸåŒ–çº¢é˜Ÿæµ‹è¯•ä»¥é™ä½æ¨¡å‹æœ‰å®³è¡Œä¸ºã€‚/ Systematic red teaming to reduce harms. [æŸ¥çœ‹ View](../_library/Red_Teaming_Language_Models_to_Reduce_Harms_Methods,_Scaling_Behaviors,_and_Lessons_Learned.pdf)
- Challenges and Applications of Large Language Models â€” LLM å½±å“ä¸æŒ‘æˆ˜æ¦‚è§ˆã€‚/ Overview of LLM impacts and challenges. [æŸ¥çœ‹ View](../_library/Challenges_and_Applications_of_Large_Language_Models.pdf)

### ğŸ“„ æ›´å¤šèµ„æ–™ / More Resources

- Challenges and Applications of Large Language Models â€” æŒ‘æˆ˜ä¸åº”ç”¨ç»¼è¿°ã€‚/ Challenges and applications survey. [æŸ¥çœ‹ View](../_library/Challenges_and_Applications_of_Large_Language_Models.pdf)
- Red Teaming Language Models to Reduce Harms â€” çº¢é˜ŸåŒ–å‡å°‘æœ‰å®³è¡Œä¸ºã€‚/ Red teaming LMs to reduce harms. [æŸ¥çœ‹ View](../_library/Red_Teaming_Language_Models_to_Reduce_Harms_Methods,_Scaling_Behaviors,_and_Lessons_Learned.pdf)

---

æœ€åæ›´æ–° / Last Updated: 2025-09-22

#### ğŸ“š ç»å…¸æ•™æ / Classic Textbooks (Collected)

- Human Compatible â€” AI å¯¹é½ä¸æ§åˆ¶é—®é¢˜ã€‚/ Alignment and control. [PDF](../_library/Human_Compatible_Artificial_Intelligence_And_The_Problem_Of_Control_Stuart_Russell.pdf)
- Superintelligence â€” è¶…äººå·¥æ™ºèƒ½çš„è·¯å¾„ä¸é£é™©ã€‚/ Superintelligence. [PDF](../_library/Superintelligence_Paths_Dangers_Strategies_By_Nick_Bostrom.pdf)
- The Ethical Algorithm â€” ç¤¾ä¼šå‹å¥½ç®—æ³•è®¾è®¡ã€‚/ Socially aware algorithm design. [PDF](../_library/The_Ethical_Algorithm_The_Science_Of_Socially_Aware_Algorithm_Design_Michael_Kearns_Aaron_Roth_Z_Library.pdf)
- Fairness and Machine Learning â€” å…¬å¹³æ€§ä¸æœºå™¨å­¦ä¹ ã€‚/ Fair ML textbook. [PDF](../_library/fairmlbook.pdf)

## ç›¸å…³ä¸»é¢˜ / Related Topics

- **01 æ·±åº¦å­¦ä¹  / Deep Learning** â†’ [../01_Deep_Learning/](../01_Deep_Learning/) â€” æ¨¡å‹ä¸æ•°æ®æ²»ç† / model and data governance
- **02 å¼ºåŒ–å­¦ä¹  / Reinforcement Learning** â†’ [../02_Reinforcement_Learning/](../02_Reinforcement_Learning/) â€” å†³ç­–ä¸­çš„å®‰å…¨çº¦æŸ / safety constraints in decision-making
- **03 å¤šæ™ºèƒ½ä½“å­¦ä¹  / Multi-Agent Learning** â†’ [../03_Multi_Agent_Learning/](../03_Multi_Agent_Learning/) â€” äº’åŠ¨é£é™©ä¸æ²»ç† / interaction risks and governance
- **04 AI åŸºç¡€ç†è®º / AI Foundations** â†’ [../04_AI_Foundations/](../04_AI_Foundations/) â€” å…¬å¹³æ€§ä¸ä¿¡æ¯è®ºå·¥å…· / fairness and information-theoretic tools
- **05 LLMs ä¸ Transformers / LLMs & Transformers** â†’ [../05_LLMs_and_Transformers/](../05_LLMs_and_Transformers/) â€” å¯¹é½/è¯„æµ‹/å®‰å…¨ / alignment, evaluation, safety
- **08 è®¡ç®—æœºè§†è§‰ / Computer Vision** â†’ [../08_Computer_Vision/](../08_Computer_Vision/) â€” å¤šæ¨¡æ€ä¸é£é™© / multimodal risks
- **97 ç§‘ç ”å†™ä½œä¸æŠ•ç¨¿ / Research Writing and Publishing** â†’ [../97_Research_Writing_and_Publishing/](../97_Research_Writing_and_Publishing/) â€” ä¼¦ç†å£°æ˜ä¸å¤ç° / ethics statements and reproducibility