# LLM ä¸ Transformers / LLMs and Transformers

## ç²¾é€‰èµ„æ–™ / Curated Resources

### â­ ç»å…¸ç²¾é€‰ / Canonical Picks

- Attention Is All You Need â€” Transformer å¼€å±±ä¹‹ä½œã€‚/ Foundational Transformer paper. [æŸ¥çœ‹ View](../_library/Attention_Is_All_You_Need.pdf)
- Language Models are Few-Shot Learners â€” GPTâ€‘3 é‡Œç¨‹ç¢‘è®ºæ–‡ã€‚/ GPTâ€‘3 milestone. [æŸ¥çœ‹ View](../_library/Language_Models_are_Few-Shot_Learners.pdf)
- Training language models to follow instructions with human feedback â€” æŒ‡ä»¤å¾®è°ƒä¸ RLHF é‡Œç¨‹ç¢‘ã€‚/ Landmark instruction-following with human feedback. [æŸ¥çœ‹ View](../_library/Training_language_models_to_follow_instructions_with_human_feedback.pdf)

### ğŸ“„ æ›´å¤šèµ„æ–™ / More Resources

- Attention Is All You Need â€” Transformer å¼€å±±ä¹‹ä½œã€‚/ Foundational Transformer paper. [æŸ¥çœ‹ View](../_library/Attention_Is_All_You_Need.pdf)
- FlashAttention â€” é«˜æ•ˆç²¾ç¡®æ³¨æ„åŠ›å®ç°ã€‚/ Fast exact attention. [æŸ¥çœ‹ View](../_library/FlashAttention_Fast_and_Memory-Efficient_Exact_Attention_with_IO-Awareness.pdf)
- LoRA: Low-Rank Adaptation â€” å‚æ•°é«˜æ•ˆå¾®è°ƒã€‚/ Parameter-efficient finetuning. [æŸ¥çœ‹ View](../_library/LoRA_Low-Rank_Adaptation_of_Large_Language_Models.pdf)
- Retrieval-Augmented Generation (RAG) â€” æ£€ç´¢å¢å¼ºç”Ÿæˆã€‚/ RAG overview. [æŸ¥çœ‹ View](../_library/Retrieval-Augmented_Generation_for_Knowledge-Intensive_NLP_Tasks.pdf)
- Direct Preference Optimization (DPO) â€” ç›´æ¥åå¥½ä¼˜åŒ–ã€‚/ DPO paper. [æŸ¥çœ‹ View](../_library/Direct_Preference_Optimization_Your_Language_Model_is_Secretly_a_Reward_Model.pdf)
- Learning to summarize from human feedback â€” äººç±»åé¦ˆå­¦ä¹ æ‘˜è¦ã€‚/ Summarization via RLHF. [æŸ¥çœ‹ View](../_library/Learning_to_summarize_from_human_feedback.pdf)
- Training LMs to follow instructions with human feedback â€” æŒ‡ä»¤å¾®è°ƒã€‚/ Instruction tuning with human feedback. [æŸ¥çœ‹ View](../_library/Training_language_models_to_follow_instructions_with_human_feedback.pdf)
- Scaling Instruction-Finetuned LMs â€” æŒ‡ä»¤å¾®è°ƒè§„æ¨¡åŒ–ã€‚/ Scaling instruction tuning. [æŸ¥çœ‹ View](../_library/Scaling_Instruction-Finetuned_Language_Models.pdf)
- Language Models are Few-Shot Learners â€” GPT-3 è®ºæ–‡ã€‚/ GPT-3. [æŸ¥çœ‹ View](../_library/Language_Models_are_Few-Shot_Learners.pdf)
- Large Language Models: A Survey â€” LLMç»¼è¿°ã€‚/ LLM survey. [æŸ¥çœ‹ View](../_library/Large_Language_Models_A_Survey.pdf)
- Harnessing the Power of LLMs in Practice â€” ChatGPT ç­‰å®è·µç»¼è¿°ã€‚/ Practical survey on ChatGPT and beyond. [æŸ¥çœ‹ View](../_library/Harnessing_the_Power_of_LLMs_in_Practice_A_Survey_on_ChatGPT_and_Beyond.pdf)
- Large Language Models Can Self-Improve â€” è‡ªæˆ‘æ”¹å–„ã€‚/ Self-improvement in LLMs. [æŸ¥çœ‹ View](../_library/Large_Language_Models_Can_Self-Improve.pdf)
- Self-Rewarding Language Models â€” è‡ªå¥–åŠ±è¯­è¨€æ¨¡å‹ã€‚/ Self-rewarding LMs. [æŸ¥çœ‹ View](../_library/Self-Rewarding_Language_Models.pdf)
- Efficient Training of LMs to Fill-in-the-Middle â€” FIM è®­ç»ƒã€‚/ FIM training. [æŸ¥çœ‹ View](../_library/Efficient_Training_of_Language_Models_to_Fill_in_the_Middle.pdf)

---

æœ€åæ›´æ–° / Last Updated: 2025-09-22
