# å¤šæ™ºèƒ½ä½“å­¦ä¹  / Multi-Agent Learning

## ä¸»é¢˜ä»‹ç» / Topic Introduction

å¤šæ™ºèƒ½ä½“å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„é‡è¦åˆ†æ”¯ï¼Œç ”ç©¶å¤šä¸ªæ™ºèƒ½ä½“åœ¨å…±äº«ç¯å¢ƒä¸­çš„äº¤äº’ã€åä½œä¸ç«äº‰ã€‚è¿™ä¸€é¢†åŸŸç»“åˆäº†åšå¼ˆè®ºã€å¼ºåŒ–å­¦ä¹ ã€åˆ†å¸ƒå¼ç³»ç»Ÿç­‰å¤šä¸ªå­¦ç§‘ï¼Œæ—¨åœ¨ç†è§£å’Œè®¾è®¡èƒ½å¤Ÿåœ¨å¤æ‚å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­æœ‰æ•ˆå­¦ä¹ å’Œå†³ç­–çš„ç³»ç»Ÿã€‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (MARL)ä½œä¸ºæ ¸å¿ƒæŠ€æœ¯ï¼Œä¸ºè§£å†³ç°å®ä¸–ç•Œä¸­çš„å¤æ‚åä½œé—®é¢˜æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œå®è·µæ–¹æ³•ã€‚

Multi-agent learning is an important branch of artificial intelligence that studies the interaction, cooperation, and competition of multiple agents in shared environments. This field combines game theory, reinforcement learning, distributed systems, and other disciplines, aiming to understand and design systems that can effectively learn and make decisions in complex multi-agent environments. Multi-agent reinforcement learning (MARL) serves as a core technology, providing important theoretical foundations and practical methods for solving complex cooperation problems in the real world.

## æ¨èå­¦ä¹ è·¯å¾„ / Recommended Learning Path

### ğŸ—ï¸ åŸºç¡€ç†è®º / Foundational Theory

1. åšå¼ˆè®ºåŸºç¡€ / Game theory foundations
2. å•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  / Single-agent reinforcement learning
3. åˆ†å¸ƒå¼ç³»ç»Ÿæ¦‚å¿µ / Distributed systems concepts

### ğŸ§  æ ¸å¿ƒæ¦‚å¿µ / Core Concepts

1. å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç®—æ³• / Multi-agent reinforcement learning algorithms
2. åè°ƒä¸åˆä½œæœºåˆ¶ / Coordination and cooperation mechanisms
3. é€šä¿¡ä¸ä¿¡æ¯å…±äº« / Communication and information sharing

### ğŸš€ å‰æ²¿åº”ç”¨ / Advanced Applications

1. å¤šæœºå™¨äººåä½œ / Multi-robot collaboration
2. è‡ªåŠ¨é©¾é©¶è½¦è¾†åè°ƒ / Autonomous vehicle coordination
3. åˆ†å¸ƒå¼èµ„æºç®¡ç† / Distributed resource management

## ç²¾é€‰èµ„æ–™ / Curated Resources

### â­ ç»å…¸ç²¾é€‰ / Canonical Picks

- Multiagent Systems (Shoham & Leyton-Brown) â€” å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç»å…¸æ•™æã€‚/ Classic textbook. [æŸ¥çœ‹ View](../_library/Multiagent_Systems_Shoham_Leyton_Brown.pdf)
- QMIX Monotonic Value Function Factorisation â€” MARL ä»£è¡¨æ€§ç®—æ³•ã€‚/ Representative MARL algorithm. [æŸ¥çœ‹ View](../_library/QMIX_Monotonic_Value_Function_Factorisation_for_Deep_Multi-Agent_Reinforcement_Learning.pdf)
- Counterfactual Multi-Agent Policy Gradients â€” COMA ç®—æ³•ã€‚/ COMA algorithm. [æŸ¥çœ‹ View](../_library/Counterfactual_Multi-Agent_Policy_Gradients.pdf)

### ğŸ“š ç»å…¸æ•™æ / Classic Textbooks

 
#### Multi-Agent Reinforcement Learning Foundations

**ä½œè€…/Authors**: Michael L. Littman, Liviu Panait, Jakob Foerster, et al.  
**å¹´ä»½/Year**: 2024  
**æ ‡ç­¾/Tags**: `å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ` `åè°ƒ` `åšå¼ˆè®º` `MARL` `Coordination` `Game Theory`

æœ¬ä¹¦ç³»ç»Ÿæ¢³ç†äº†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€ç†è®ºä¸ç®—æ³•ï¼ŒåŒ…æ‹¬ centralized criticã€self-playã€è‡ªç»„ç»‡åˆä½œç­‰æœºåˆ¶ï¼›è®¨è®ºå¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„å­¦ä¹ æŒ‘æˆ˜ï¼ˆå¦‚éå¹³ç¨³æ€§ã€éƒ¨åˆ†å¯è§‚å¯Ÿæ€§ã€é€šä¿¡çº¦æŸï¼‰ä¸å¯¹åº”æ–¹æ³•ï¼Œæ¶µç›–ä»ç‹¬ç«‹å­¦ä¹ åˆ°è”åˆå­¦ä¹ çš„å¤šç§æ€è·¯ã€‚

This book systematically outlines the foundations and algorithms of multi-agent reinforcement learning, including centralized critic, self-play, and emergent cooperation mechanisms. It explores learning challenges in multi-agent environments such as non-stationarity, partial observability, and communication constraints, providing corresponding solutions.

**æ¨èè¯»è€…/Recommended For**: å·²å…·å¤‡å¼ºåŒ–å­¦ä¹ åŸºç¡€ã€å…³æ³¨å¤šæ™ºèƒ½ä½“åä½œå’Œåšå¼ˆå»ºæ¨¡çš„å­¦ä¹ è€…å’Œç ”ç©¶è€…ã€‚/ For readers with RL foundations, interested in multi-agent coordination, game-theoretic modeling, and scalable learning.

**é“¾æ¥/Link**: [../_library/Multi-Agent_Reinforcement_Learning_Foundations.pdf](../_library/Multi-Agent_Reinforcement_Learning_Foundations.pdf)

---

### ğŸ“„ æ›´å¤šèµ„æ–™ / More Resources

- The StarCraft Multi-Agent Challenge â€” SC2 å¤šæ™ºèƒ½ä½“æŒ‘æˆ˜ã€‚/ SMAC benchmark. [æŸ¥çœ‹ View](../_library/The_StarCraft_Multi-Agent_Challenge.pdf)
- The Hanabi Challenge â€” Hanabi åä½œæŒ‘æˆ˜ã€‚/ Hanabi benchmark. [æŸ¥çœ‹ View](../_library/The_Hanabi_Challenge_A_New_Frontier_for_AI_Research.pdf)
- The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games â€” å¤šæ™ºèƒ½ä½“åä½œä¸­ PPO çš„æœ‰æ•ˆæ€§ã€‚/ PPO in cooperative MARL. [æŸ¥çœ‹ View](../_library/The_Surprising_Effectiveness_of_PPO_in_Cooperative,_Multi-Agent_Games.pdf)
- Counterfactual Multi-Agent Policy Gradients â€” COMA ç®—æ³•ã€‚/ COMA algorithm. [æŸ¥çœ‹ View](../_library/Counterfactual_Multi-Agent_Policy_Gradients.pdf)
- Value-Decomposition Networks For Cooperative Multi-Agent Learning â€” VDNã€‚/ Value decomposition. [æŸ¥çœ‹ View](../_library/Value-Decomposition_Networks_For_Cooperative_Multi-Agent_Learning.pdf)
- QMIX Monotonic Value Function Factorisation â€” QMIXã€‚/ Monotonic value factorization. [æŸ¥çœ‹ View](../_library/QMIX_Monotonic_Value_Function_Factorisation_for_Deep_Multi-Agent_Reinforcement_Learning.pdf)

#### ğŸ“š ç»å…¸æ•™æï¼ˆå·²æ”¶å½•ï¼‰ / Classic Textbooks (Collected)

- Algorithmic Game Theory â€” ç®—æ³•åšå¼ˆè®ºé‡è¦æ–‡é›†ã€‚/ Influential compendium. [PDF](../_library/Algorithmic_Game_Theory.pdf)
- Multiagent Systems: A Modern Approach to Distributed AI â€” å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç»å…¸æ•™æï¼ˆæ–‡é›†ï¼‰ã€‚/ Classic textbook. [PDF](../_library/Multiagent_Systems_A_Modern_Approach_To_Distributed_Artificial_Intelligence_Gerhard_Weiss.pdf)
- Distributed Control of Robotic Networks â€” å›¾è®º/ä¸€è‡´æ€§/åˆ†å¸ƒå¼æ§åˆ¶åŸºç¡€ã€‚/ Foundations in distributed control. [PDF](../_library/DCRN_Bullocortesmartinez_10mar09.pdf)


## ç›¸å…³ä¸»é¢˜ / Related Topics

- **00 ä¸–ç•Œæ¨¡å‹ä¸å…·èº«æ™ºèƒ½ / World Models & Embodied AI** â†’ [../00_World_Models_and_Embodied_AI/](../00_World_Models_and_Embodied_AI/) â€” å…·èº«åä½œä¸æ§åˆ¶ / embodied coordination and control
- **01 æ·±åº¦å­¦ä¹  / Deep Learning** â†’ [../01_Deep_Learning/](../01_Deep_Learning/) â€” è¡¨è¾¾ä¸é€šä¿¡å»ºæ¨¡ / representation and communication modeling
- **02 å¼ºåŒ–å­¦ä¹  / Reinforcement Learning** â†’ [../02_Reinforcement_Learning/](../02_Reinforcement_Learning/) â€” ç­–ç•¥ä¼˜åŒ–ä¸åšå¼ˆæ¡†æ¶ / policy optimization and game-theoretic frameworks
- **04 AI åŸºç¡€ç†è®º / AI Foundations** â†’ [../04_AI_Foundations/](../04_AI_Foundations/) â€” åšå¼ˆ/ä¼˜åŒ–/æ¦‚ç‡å·¥å…· / game theory, optimization, probability
- **05 LLMs ä¸ Transformers / LLMs & Transformers** â†’ [../05_LLMs_and_Transformers/](../05_LLMs_and_Transformers/) â€” å¤šæ™ºèƒ½ä½“é€šä¿¡ä¸è¯­è¨€å»ºæ¨¡ / communication and language modeling
- **06 è®­ç»ƒåŠ¨æ€ä¸æ³›åŒ– / Training Dynamics and Generalization** â†’ [../06_Training_Dynamics_and_Generalization/](../06_Training_Dynamics_and_Generalization/) â€” éå¹³ç¨³æ€§ä¸æ³›åŒ– / non-stationarity and generalization
- **08 è®¡ç®—æœºè§†è§‰ / Computer Vision** â†’ [../08_Computer_Vision/](../08_Computer_Vision/) â€” å¤šè§†åä½œä¸æ„ŸçŸ¥ / multi-view and perception
- **97 ç§‘ç ”å†™ä½œä¸æŠ•ç¨¿ / Research Writing and Publishing** â†’ [../97_Research_Writing_and_Publishing/](../97_Research_Writing_and_Publishing/) â€” è®ºæ–‡å†™ä½œ / writing
- **LLMs ä¸ Transformers** / LLMs & Transformers â†’ [../05_LLMs_and_Transformers/](../05_LLMs_and_Transformers/)

## å­¦ä¹ å»ºè®® / Study Recommendations

### å¯¹äºåˆå­¦è€… / For Beginners

å»ºè®®å…ˆæŒæ¡å•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ï¼Œç„¶åå­¦ä¹ åšå¼ˆè®ºçš„åŸºæœ¬æ¦‚å¿µï¼Œå†è¿›å…¥å¤šæ™ºèƒ½ä½“å­¦ä¹ é¢†åŸŸã€‚

It is recommended to first master the fundamentals of single-agent reinforcement learning, then learn basic concepts of game theory, before entering the field of multi-agent learning.

### å¯¹äºè¿›é˜¶å­¦ä¹ è€… / For Advanced Learners

æ·±å…¥ç ”ç©¶å…·ä½“çš„MARLç®—æ³•å®ç°ï¼Œå…³æ³¨æœ€æ–°çš„ç ”ç©¶è¿›å±•ï¼Œç‰¹åˆ«æ˜¯æ·±åº¦å­¦ä¹ åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚é‡ç‚¹å­¦ä¹ åè°ƒæœºåˆ¶å’Œé€šä¿¡ç­–ç•¥çš„è®¾è®¡ã€‚

Study specific MARL algorithm implementations in depth, pay attention to the latest research developments, especially the application of deep learning in multi-agent systems. Focus on coordination mechanisms and communication strategy design.

---

æœ€åæ›´æ–° / Last Updated: 2025å¹´9æœˆ22æ—¥ / September 22, 2025
