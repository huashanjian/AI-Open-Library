# 🤝 如何贡献资料 · How to Contribute to This Library

欢迎你加入我们的知识共建！这个项目致力于构建一个系统化、长期可用的 AI 学习资料库。  
我们欢迎任何人推荐高质量、合法公开的资料（如书籍、论文、综述、课程笔记等），帮助更多学习者少走弯路。

We’re building an open, structured AI learning library—and your recommendations can help thousands of learners.  
Feel free to suggest books, papers, course materials, or well-organized notes (as long as they are publicly shareable).

---

## 📮 提交方式 · How to Submit

你可以通过以下方式提交资料推荐：

- ✉️ 发送邮件至：**junhuayao41@gmail.com**  
- 🐙 在本仓库创建 [GitHub Issue](https://github.com/your-repo-name/issues)（推荐使用标题 `📚 资料推荐`）

Please send your recommendation via:

- Email: **junhuayao41@gmail.com**
- GitHub Issues: [Submit Here](https://github.com/your-repo-name/issues) (recommended title: `📚 Resource Suggestion`)

---

### 📧 邮件推荐模板 · Email Suggestion Template

你可以复制以下内容作为邮件正文格式：

邮件主题 / Subject:
📚 推荐资料：书名或主题名（可选）

邮件正文 / Body:

你好，我在 GitHub 上看到了你建立的 AI 学习资料库，觉得很棒！我这边有一个资料想推荐给你，信息如下：

书名 / Title: 《强化学习：原理与算法》
作者 / Author: Richard S. Sutton, Andrew G. Barto
标签 / Tags: RL / policy gradient / MDP
所属主题 / Topics: 强化学习、AI基础理论
推荐读者 / Recommended for: 强化学习入门者、理论研究者
简介 / Summary: 这本书是强化学习领域最具代表性的教材之一，内容系统、理论扎实。
来源 / Source: 公开版PDF来自作者官网：https://incompleteideas.net/book/the-book.html

如合适，欢迎收录到你的资料库中。谢谢你整理这些资料！

署名 / Signature:
你的名字（或GitHub ID）



👆 如果你不清楚某项内容，可以留空或写“暂缺”，我们会帮你补全。
Even if you’re not sure about some fields, you can leave them blank. We'll help complete the details.


## 🧾 推荐资料格式 · Submission Format (Markdown, bilingual preferred)

推荐内容最好按以下格式提交（用于 GitHub Issues 或正文中）：


### 📘 书名 Title:  
《强化学习：原理与算法》 · Reinforcement Learning: An Introduction

📂 所属主题 Topics:  
[02 强化学习 Reinforcement Learning]  
[04 AI 基础理论 Foundations of AI]

✍️ 作者 Author(s):  
Richard S. Sutton, Andrew G. Barto

🏷️ 标签 Tags:  
RL / policy gradient / MDP / theory

👥 推荐读者 Recommended For:  
强化学习初学者，或希望补全理论基础的研究者  
Beginner RL learners, or researchers looking to strengthen their theoretical understanding

📝 简介 Summary:  
该书是强化学习领域的经典教材，系统介绍了马尔可夫决策过程、值函数、策略优化等核心内容，理论严谨，配套实验丰富。  
This book is a RL classic, covering MDPs, value functions, policy gradients, and more, with a strong theoretical foundation and practical exercises.

📦 来源 Source:  
作者官网开放下载，由 XXX 推荐 / 整理上传  
Official website or public release; recommended and uploaded by XXX


## 🖋️ 署名与收录说明 · Credits & Archiving

* 所有贡献将标注你的 GitHub ID 或署名（如你愿意）
* 推荐资料会由维护者归类至对应主题，并附跳转链接
* 若你愿意，我们会在 `library_catalog.md` 中公开感谢你
* 如资料来自公开渠道（如 arXiv, MIT OCW），请注明来源链接；如为自制笔记，建议附 GitHub / Notion 页面

All contributors will be credited (unless they prefer anonymity).
Resources will be properly categorized, archived, and referenced in the library index.
If the resource is public (e.g. arXiv, MIT OCW), please include a source link.



## ✅ 可接受的资料类型 · Acceptable Resource Types

我们欢迎如下类型的资料，只要它们 **合法公开**、**内容清晰**、**主题明确**：

* ✅ 开放获取的 PDF 教材、综述、论文集
* ✅ 官方课程资料、Project Notes、Syllabus
* ✅ 自整理的结构化学习笔记
* ✅ 中文资料亦欢迎（建议附英文简介）

We welcome:

* ✅ Open-access textbooks, surveys, paper compilations (PDFs)
* ✅ Official course documents, lecture notes, syllabi
* ✅ Self-organized study notes (if well-structured)
* ✅ Non-English resources (Chinese welcome!)—please provide English summary if possible



## 🌱 感谢你的加入 · Thank You for Building Together

一个资料库不仅是资源的汇总，更是认知的延展。
我们相信：越是系统、可信、共享的知识，越能激发出更多有力量的学习者。
感谢你愿意带来属于你的那一份知识，它会在某处照亮他人。

This library is more than a collection—it's a shared map of understanding.
We believe structured, open knowledge inspires better learners.
Thank you for sharing yours—it may be the spark someone else needed. 🌍✨
