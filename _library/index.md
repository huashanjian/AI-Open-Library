# ğŸ“š AI å¼€æ”¾èµ„æ–™åº“ Â· Library Indexï¼ˆæ—¶é—´æ’åºï¼‰

è¿™é‡Œè®°å½•äº†æ‰€æœ‰å·²ä¸Šä¼ èµ„æ–™çš„æ—¶é—´ã€ä¸»é¢˜å½’å±ã€æ¨èäººç¾¤ä¸èµ„æ–™è¯´æ˜ï¼Œå¹¶æä¾›è·³è½¬é“¾æ¥ã€‚æ‰€æœ‰æ–‡ä»¶å‡å­˜æ”¾äº `_library/` ç›®å½•ä¸­ï¼Œå»ºè®®ç»“åˆå„ä¸»é¢˜ç›®å½•é˜…è¯»ã€‚

---

## ğŸ—“ 2025å¹´9æœˆ21ä¸Šä¼  Â· Uploaded in Sep 21 2025

---

### ğŸ“˜ Understanding Deep Learning Requires Rethinking Generalization  
ğŸ“‚ æ‰€å±ä¸»é¢˜ Topics:  
[06 è®­ç»ƒåŠ¨æ€ä¸æ³›åŒ–æœºåˆ¶ Training Dynamics & Generalization]  
[01 æ·±åº¦å­¦ä¹ åŸºç¡€ Deep Learning]  
ğŸ“„ [ç‚¹å‡»æŸ¥çœ‹ PDF Â· View PDF](./Understanding_Deep_Learning_Requires_Rethinking_Generalization.pdf)  
âœï¸ ä½œè€… Authors: Chiyuan Zhang, Samy Bengio, Yoram Singer, et al.  
ğŸ·ï¸ æ ‡ç­¾ Tags: generalization / deep learning / overfitting  
ğŸ‘¥ æ¨èè¯»è€… Recommended For:  
å¯¹æ·±åº¦ç½‘ç»œè®­ç»ƒè¡Œä¸ºæ„Ÿå…´è¶£çš„å­¦ä¹ è€…ï¼Œå°¤å…¶æ˜¯å¯¹â€œä¸ºä½•èƒ½æ‹Ÿåˆå…¨éƒ¨æ•°æ®å´ä»æ³›åŒ–â€é—®é¢˜æ„Ÿå…´è¶£çš„ç ”ç©¶è€…ã€‚  
For learners interested in the training behavior of deep networks, especially those puzzled by "perfect fitting yet strong generalization".

ğŸ“ ç®€ä»‹ Summary:  
æœ¬è®ºæ–‡é€šè¿‡å®éªŒæ­ç¤ºæ·±åº¦ç½‘ç»œåœ¨è®­ç»ƒé›†æ‹Ÿåˆå…¨éƒ¨æ•°æ®çš„åŒæ—¶ä¾ç„¶åœ¨æµ‹è¯•é›†æ³›åŒ–è‰¯å¥½ï¼ŒæŒ‘æˆ˜äº†ç»å…¸çš„ç»Ÿè®¡å­¦ä¹ ç†è®ºã€‚  
This work experimentally reveals that deep networks can generalize well on test sets even when they perfectly fit the training data, challenging classical statistical learning theories.

---

### ğŸ¤– Underactuated Robotics  
ğŸ“‚ æ‰€å±ä¸»é¢˜ Topics:  
[00 ä¸–ç•Œæ¨¡å‹ä¸å…·èº«æ™ºèƒ½ World Models & Embodied AI]  
[02 å¼ºåŒ–å­¦ä¹  Reinforcement Learning]  
ğŸ“„ [ç‚¹å‡»æŸ¥çœ‹ PDF Â· View PDF](./Underactuated_Robotics_Russ_Tedrake.pdf)  
âœï¸ ä½œè€… Author: Russ Tedrake (MIT OpenCourseWare)  
ğŸ·ï¸ æ ‡ç­¾ Tags: robotics / dynamics / underactuation  
ğŸ‘¥ æ¨èè¯»è€… Recommended For:  
æœºå™¨äººå­¦ä¹ åˆå­¦è€…ã€å…·èº«æ™ºèƒ½ç ”ç©¶è€…ã€å¯¹åŠ¨åŠ›ç³»ç»Ÿæ§åˆ¶å»ºæ¨¡æ„Ÿå…´è¶£çš„å·¥ç¨‹ä¸“ä¸šå­¦ç”Ÿã€‚  
Beginner roboticists, embodied AI researchers, and engineering students interested in control and dynamical modeling.

ğŸ“ ç®€ä»‹ Summary:  
è¯¥æ•™ææ·±å…¥ä»‹ç»äº†æ¬ é©±åŠ¨æœºå™¨äººç³»ç»Ÿçš„å»ºæ¨¡ä¸æ§åˆ¶ç­–ç•¥ï¼Œæ¶µç›–å€’ç«‹æ‘†ã€LQR ç­‰å…³é”®ç³»ç»Ÿï¼Œé…å¥—æœ‰ MIT å¼€æºè¯¾ç¨‹èµ„æºã€‚  
This textbook introduces modeling and control strategies for underactuated robotic systems, including inverted pendulum and LQR, and is complemented by MITâ€™s open course materials.

---

### ğŸ¤ Multi-Agent Reinforcement Learning Foundations  
ğŸ“‚ æ‰€å±ä¸»é¢˜ Topics:  
[03 å¤šæ™ºèƒ½ä½“å­¦ä¹  Multi-Agent Learning]  
[02 å¼ºåŒ–å­¦ä¹  Reinforcement Learning]  
[04 AI åŸºç¡€ç†è®º Foundations of AI]  
ğŸ“„ [ç‚¹å‡»æŸ¥çœ‹ PDF Â· View PDF](./Multi-Agent_Reinforcement_Learning_Foundations.pdf)  
âœï¸ ä½œè€… Authors: Michael L. Littman, Liviu Panait, Jakob Foerster, et al.  
ğŸ·ï¸ æ ‡ç­¾ Tags: MARL / coordination / game theory  
ğŸ‘¥ æ¨èè¯»è€… Recommended For:  
å·²å…·å¤‡å¼ºåŒ–å­¦ä¹ åŸºç¡€ã€å…³æ³¨å¤šæ™ºèƒ½ä½“åä½œå’Œåšå¼ˆå»ºæ¨¡çš„å­¦ä¹ è€…å’Œç ”ç©¶è€…ã€‚  
For readers with RL foundations, interested in multi-agent coordination, game-theoretic modeling, and scalable learning.

ğŸ“ ç®€ä»‹ Summary:  
æœ¬ä¹¦ç³»ç»Ÿæ¢³ç†äº†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€ç†è®ºä¸ç®—æ³•ï¼ŒåŒ…æ‹¬ centralized criticã€self-playã€è‡ªç»„ç»‡åˆä½œç­‰é‡è¦æœºåˆ¶ã€‚  
This book systematically outlines the foundations and algorithms of multi-agent reinforcement learning, including centralized critic, self-play, and emergent cooperation mechanisms.


---

## ğŸ“„ æ›´å¤šèµ„æº Â· More Resources

- World Models â€” [View](./World_Models.pdf) â€” (Ha & Schmidhuber)
- Mastering Diverse Domains through World Models â€” [View](./Mastering_Diverse_Domains_through_World_Models.pdf)
- Mastering Atari with Discrete World Models â€” [View](./Mastering_Atari_with_Discrete_World_Models.pdf) â€” (ICLR 2021)
- Dream to Control Learning Behaviors by Latent Imagination â€” [View](./Dream_to_Control_Learning_Behaviors_by_Latent_Imagination.pdf) â€” (ICLR 2020)
- Learning Latent Dynamics for Planning from Pixels â€” [View](./Learning_Latent_Dynamics_for_Planning_from_Pixels.pdf)
- What Does it Mean for a Neural Network to Learn a World Model â€” [View](./What_Does_it_Mean_for_a_Neural_Network_to_Learn_a_World_Model.pdf) â€” (Li, Viegas & Wattenberg)
- World Knowledge from AI Image Generation for Robot Control â€” [View](./World_Knowledge_from_AI_Image_Generation_for_Robot_Control.pdf)
- Playing Atari with Deep Reinforcement Learning â€” [View](./Playing_Atari_with_Deep_Reinforcement_Learning.pdf)
- Proximal Policy Optimization Algorithms â€” [View](./Proximal_Policy_Optimization_Algorithms.pdf)
- Soft Actor-Critic Algorithms and Applications â€” [View](./Soft_Actor-Critic_Algorithms_and_Applications.pdf)
- The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games â€” [View](./The_Surprising_Effectiveness_of_PPO_in_Cooperative,_Multi-Agent_Games.pdf)
- Value-Decomposition Networks For Cooperative Multi-Agent Learning â€” [View](./Value-Decomposition_Networks_For_Cooperative_Multi-Agent_Learning.pdf)
- QMIX Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning â€” [View](./QMIX_Monotonic_Value_Function_Factorisation_for_Deep_Multi-Agent_Reinforcement_Learning.pdf) â€” (Rashid et al.)
- Model-based Reinforcement Learning A Survey â€” [View](./Model-based_Reinforcement_Learning_A_Survey.pdf)
- Deep Residual Learning for Image Recognition â€” [View](./Deep_Residual_Learning_for_Image_Recognition.pdf)
- Batch Normalization â€” [View](./Batch_Normalization_Accelerating_Deep_Network_Training_by_Reducing_Internal_Covariate_Shift.pdf) â€” (2015)
- Layer Normalization â€” [View](./Layer_Normalization.pdf)
- Adam A Method for Stochastic Optimization â€” [View](./Adam_A_Method_for_Stochastic_Optimization.pdf) â€” (Kingma & Ba)
- SGDR Stochastic Gradient Descent with Warm Restarts â€” [View](./SGDR_Stochastic_Gradient_Descent_with_Warm_Restarts.pdf) â€” (ICLR 2017)
- Scaling Laws for Neural Language Models â€” [View](./Scaling_Laws_for_Neural_Language_Models.pdf)
