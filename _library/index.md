# ğŸ“š AI å¼€æ”¾èµ„æ–™åº“ Â· Library Indexï¼ˆæ—¶é—´æ’åºï¼‰

è¿™é‡Œè®°å½•äº†æ‰€æœ‰å·²ä¸Šä¼ èµ„æ–™çš„æ—¶é—´ã€ä¸»é¢˜å½’å±ã€æ¨èäººç¾¤ä¸èµ„æ–™è¯´æ˜ï¼Œå¹¶æä¾›è·³è½¬é“¾æ¥ã€‚æ‰€æœ‰æ–‡ä»¶å‡å­˜æ”¾äº `_library/` ç›®å½•ä¸­ï¼Œå»ºè®®ç»“åˆå„ä¸»é¢˜ç›®å½•é˜…è¯»ã€‚

---

## ğŸ—“ 2025å¹´9æœˆ21ä¸Šä¼  Â· Uploaded in Sep 21 2025

---

### ğŸ“˜ Understanding Deep Learning Requires Rethinking Generalization  
ğŸ“‚ æ‰€å±ä¸»é¢˜ Topics:  
[06 è®­ç»ƒåŠ¨æ€ä¸æ³›åŒ–æœºåˆ¶ Training Dynamics & Generalization]  
[01 æ·±åº¦å­¦ä¹ åŸºç¡€ Deep Learning]  
ğŸ“„ [ç‚¹å‡»æŸ¥çœ‹ PDF Â· View PDF](./UnderstandingDeepLearning_05_29_25_C.pdf)  
âœï¸ ä½œè€… Authors: Chiyuan Zhang, Samy Bengio, Yoram Singer, et al.  
ğŸ·ï¸ æ ‡ç­¾ Tags: generalization / deep learning / overfitting  
ğŸ‘¥ æ¨èè¯»è€… Recommended For:  
å¯¹æ·±åº¦ç½‘ç»œè®­ç»ƒè¡Œä¸ºæ„Ÿå…´è¶£çš„å­¦ä¹ è€…ï¼Œå°¤å…¶æ˜¯å¯¹â€œä¸ºä½•èƒ½æ‹Ÿåˆå…¨éƒ¨æ•°æ®å´ä»æ³›åŒ–â€é—®é¢˜æ„Ÿå…´è¶£çš„ç ”ç©¶è€…ã€‚  
For learners interested in the training behavior of deep networks, especially those puzzled by "perfect fitting yet strong generalization".

ğŸ“ ç®€ä»‹ Summary:  
æœ¬è®ºæ–‡é€šè¿‡å®éªŒæ­ç¤ºæ·±åº¦ç½‘ç»œåœ¨è®­ç»ƒé›†æ‹Ÿåˆå…¨éƒ¨æ•°æ®çš„åŒæ—¶ä¾ç„¶åœ¨æµ‹è¯•é›†æ³›åŒ–è‰¯å¥½ï¼ŒæŒ‘æˆ˜äº†ç»å…¸çš„ç»Ÿè®¡å­¦ä¹ ç†è®ºã€‚  
This work experimentally reveals that deep networks can generalize well on test sets even when they perfectly fit the training data, challenging classical statistical learning theories.

---

### ğŸ¤– Underactuated Robotics  
ğŸ“‚ æ‰€å±ä¸»é¢˜ Topics:  
[00 ä¸–ç•Œæ¨¡å‹ä¸å…·èº«æ™ºèƒ½ World Models & Embodied AI]  
[02 å¼ºåŒ–å­¦ä¹  Reinforcement Learning]  
ğŸ“„ [ç‚¹å‡»æŸ¥çœ‹ PDF Â· View PDF](./UNDERACTUATED_ROBOTICS_book.pdf)  
âœï¸ ä½œè€… Author: Russ Tedrake (MIT OpenCourseWare)  
ğŸ·ï¸ æ ‡ç­¾ Tags: robotics / dynamics / underactuation  
ğŸ‘¥ æ¨èè¯»è€… Recommended For:  
æœºå™¨äººå­¦ä¹ åˆå­¦è€…ã€å…·èº«æ™ºèƒ½ç ”ç©¶è€…ã€å¯¹åŠ¨åŠ›ç³»ç»Ÿæ§åˆ¶å»ºæ¨¡æ„Ÿå…´è¶£çš„å·¥ç¨‹ä¸“ä¸šå­¦ç”Ÿã€‚  
Beginner roboticists, embodied AI researchers, and engineering students interested in control and dynamical modeling.

ğŸ“ ç®€ä»‹ Summary:  
è¯¥æ•™ææ·±å…¥ä»‹ç»äº†æ¬ é©±åŠ¨æœºå™¨äººç³»ç»Ÿçš„å»ºæ¨¡ä¸æ§åˆ¶ç­–ç•¥ï¼Œæ¶µç›–å€’ç«‹æ‘†ã€LQR ç­‰å…³é”®ç³»ç»Ÿï¼Œé…å¥—æœ‰ MIT å¼€æºè¯¾ç¨‹èµ„æºã€‚  
This textbook introduces modeling and control strategies for underactuated robotic systems, including inverted pendulum and LQR, and is complemented by MITâ€™s open course materials.

---

### ğŸ¤ Multi-Agent Reinforcement Learning Foundations  
ğŸ“‚ æ‰€å±ä¸»é¢˜ Topics:  
[03 å¤šæ™ºèƒ½ä½“å­¦ä¹  Multi-Agent Learning]  
[02 å¼ºåŒ–å­¦ä¹  Reinforcement Learning]  
[04 AI åŸºç¡€ç†è®º Foundations of AI]  
ğŸ“„ [ç‚¹å‡»æŸ¥çœ‹ PDF Â· View PDF](./MULTI-AGENT_RL_Book.pdf)  
âœï¸ ä½œè€… Authors: Michael L. Littman, Liviu Panait, Jakob Foerster, et al.  
ğŸ·ï¸ æ ‡ç­¾ Tags: MARL / coordination / game theory  
ğŸ‘¥ æ¨èè¯»è€… Recommended For:  
å·²å…·å¤‡å¼ºåŒ–å­¦ä¹ åŸºç¡€ã€å…³æ³¨å¤šæ™ºèƒ½ä½“åä½œå’Œåšå¼ˆå»ºæ¨¡çš„å­¦ä¹ è€…å’Œç ”ç©¶è€…ã€‚  
For readers with RL foundations, interested in multi-agent coordination, game-theoretic modeling, and scalable learning.

ğŸ“ ç®€ä»‹ Summary:  
æœ¬ä¹¦ç³»ç»Ÿæ¢³ç†äº†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€ç†è®ºä¸ç®—æ³•ï¼ŒåŒ…æ‹¬ centralized criticã€self-playã€è‡ªç»„ç»‡åˆä½œç­‰é‡è¦æœºåˆ¶ã€‚  
This book systematically outlines the foundations and algorithms of multi-agent reinforcement learning, including centralized critic, self-play, and emergent cooperation mechanisms.


---

## ğŸ“„ æ›´å¤šèµ„æº Â· More Resources

- World Models â€” [View](./World%20Models.pdf)
- Mastering Diverse Domains through World Models â€” [View](./Mastering%20Diverse%20Domains%20through%20World%20Models.pdf)
- Mastering Atari with Discrete World Models â€” [View](./Mastering%20Atari%20with%20Discrete%20World%20Models.pdf)
- Dream to Control Learning Behaviors by Latent Imagination â€” [View](./Dream%20to%20Control%20Learning%20Behaviors%20by%20Latent%20Imagination.pdf)
- Learning Latent Dynamics for Planning from Pixels â€” [View](./Learning%20Latent%20Dynamics%20for%20Planning%20from%20Pixels.pdf)
- What Does it Mean for a Neural Network to Learn a World Model â€” [View](./What%20Does%20it%20Mean%20for%20a%20Neural%20Network%20to%20Learn%20a%20World%20Model.pdf)
- World Knowledge from AI Image Generation for Robot Control â€” [View](./World%20Knowledge%20from%20AI%20Image%20Generation%20for%20Robot%20Control.pdf)
- Playing Atari with Deep Reinforcement Learning â€” [View](./Playing%20Atari%20with%20Deep%20Reinforcement%20Learning.pdf)
- Proximal Policy Optimization Algorithms â€” [View](./Proximal%20Policy%20Optimization%20Algorithms.pdf)
- Soft Actor-Critic Algorithms and Applications â€” [View](./Soft%20Actor-Critic%20Algorithms%20and%20Applications.pdf)
- The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games â€” [View](./The%20Surprising%20Effectiveness%20of%20PPO%20in%20Cooperative%2C%20Multi-Agent%20Games.pdf)
- Value-Decomposition Networks For Cooperative Multi-Agent Learning â€” [View](./Value-Decomposition%20Networks%20For%20Cooperative%20Multi-Agent%20Learning.pdf)
- QMIX Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning â€” [View](./QMIX%20Monotonic%20Value%20Function%20Factorisation%20for%20Deep%20Multi-Agent%20Reinforcement%20Learning.pdf)
- Model-based Reinforcement Learning A Survey â€” [View](./Model-based%20Reinforcement%20Learning%20A%20Survey.pdf)
- Deep Residual Learning for Image Recognition â€” [View](./Deep%20Residual%20Learning%20for%20Image%20Recognition.pdf)
- Batch Normalization â€” [View](./Batch%20Normalization%20Accelerating%20Deep%20Network%20Training%20by%20Reducing%20Internal%20Covariate%20Shift.pdf)
- Layer Normalization â€” [View](./Layer%20Normalization.pdf)
- Adam A Method for Stochastic Optimization â€” [View](./Adam%20A%20Method%20for%20Stochastic%20Optimization.pdf)
- SGDR Stochastic Gradient Descent with Warm Restarts â€” [View](./SGDR%20Stochastic%20Gradient%20Descent%20with%20Warm%20Restarts.pdf)
- Scaling Laws for Neural Language Models â€” [View](./Scaling%20Laws%20for%20Neural%20Language%20Models.pdf)
